---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. Suspendisse condimentum, libero vel tempus mattis, risus risus vulputate libero, elementum fermentum mi neque vel nisl. Maecenas facilisis maximus dignissim. Curabitur mattis vulputate dui, tincidunt varius libero luctus eu. Mauris mauris nulla, scelerisque eget massa id, tincidunt congue felis. Sed convallis tempor ipsum rhoncus viverra. Pellentesque nulla orci, accumsan volutpat fringilla vitae, maximus sit amet tortor. Aliquam ultricies odio ut volutpat scelerisque. Donec nisl nisl, porttitor vitae pharetra quis, fringilla sed mi. Fusce pretium dolor ut aliquam consequat. Cras volutpat, tellus accumsan mattis molestie, nisl lacus tempus massa, nec malesuada tortor leo vel quam. Aliquam vel ex consectetur, vehicula leo nec, efficitur eros. Donec convallis non urna quis feugiat.

My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>



- [Multi-class AUC Optimization for Robust Small-footprint Keyword Spotting with Limited Training Data](https://arxiv.org/abs/2107.05859), Xu Menglong, Li Shengqiang, Liang Chengdong, Zhang Xiao-Lei, **INTERSPEECH 2022**, [Code](https://github.com/mlxu995/Multi-class-AUC-loss)
- [Transformer-based end-to-end speech recognition with local dense synthesizer attention](https://arxiv.org/abs/2010.12155), Xu Menglong, Li Shengqiang, Zhang Xiao-Lei, **ICASSP 2021**, [Code](https://github.com/mlxu995/multihead-LDSA)
- [Depthwise separable convolutional resnet with squeeze-and-excitation blocks for small-footprint keyword spotting](https://arxiv.org/abs/2004.12200), Xu Menglong, Zhang Xiao-Lei, **INTERSPEECH 2020**
- [Wekws: A production first small-footprint end-to-end keyword spotting toolkit](https://arxiv.org/pdf/2210.16743.pdf), Wang Jie, Xu Menglong, Hou Jingyong, Zhang Binbin, Zhang Xiao-Lei, Xie Lei, Pan Fuping, **ICASSP 2023**, [Code](https://github.com/wenet-e2e/wekws)
- AUC optimization for deep learning-based voice activity detection, Zhang Xiao-Lei, Xu Menglong, **EURASIP 2022**
- Transformer-based end-to-end speech recognition with residual gaussian-based self-attention, Liang Chengdong, Xu Menglong, Zhang Xiao-Lei, **INTERSPEECH 2021**
- [Efficient conformer-based speech recognition with linear attention](https://arxiv.org/abs/2104.06865), Li Shengqiang, Xu Menglong, Zhang Xiao-Lei, **APSIPA 2021**
- [Conformer-based end-to-end speech recognition with rotary position embedding](https://arxiv.org/abs/2107.05907), Li Shengqiang, Xu Menglong, Zhang Xiao-Lei, **APSIPA 2021**
- TouchASP: Elastic Automatic Speech Perception that Everyone Can Touch, Song Xingchen, Liang Chengdong, Zhang Binbin, Zhang Pengshen, Wang ZiYu, Ma Youcheng, Xu Menglong, Wang Lin, Wu Di, Pan Fuping, others, **arXiv 2024**
- Libri-adhoc40: A dataset collected from synchronized ad-hoc microphone arrays, Guan Shanzheng, Liu Shupei, Chen Junqi, Zhu Wenbo, Li Shengqiang, Tan Xu, Yang Ziye, Xu Menglong, Chen Yijiang, Liang Chengdong, others, **APSIPA 2021**



# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
